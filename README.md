Υλοποιήθηκε από τους φοιτητές Μιχαήλ Σολομωνίδη και Κωνσταντίνο Κιούση
Αυτό το repository περιέχει τους κώδικες που υλοποιήθηκαν στα πλαίσια της εργασίας που εκφωνείται στο αυτό το αρχείο αλλά και τις σχετικές αναφορές.
-
-
-
Για την εργασία θα χρησιμοποιηθεί το Apache Spark για την επεξεργασία δεδομένων. Η εργασία αφορά την εξαγωγή πληροφορίας από δεδομένα (MapReduce, SparkSQL).
Η παρούσα εξαμηνιαία εργασία απαιτεί ανάλυση σε μεγάλα σύνολα δεδομένων, χρησιμοποιώντας τεχνικές που εφαρμόζονται σε έργα επιστήμης δεδομένων. Τα εργαλεία που θα χρησιμοποιηθούν είναι το Apache Hadoop (έκδοση>=3.3) και το Apache Spark (έκδοση>=3.5).
-
Καλείστε να χρησιμοποιήσετε τους πόρους που σας διατίθενται στο ειδικά διαμορφωμένο περιβάλλον που έχει δημιουργηθεί για εσάς και στο οποίο μπορείτε να αποκτήσετε πρόσβαση ακολουθώντας τους εργαστηριακούς οδηγούς του μαθήματος. 
-
Συνοπτικά, ο σκοπός της εργασίας είναι:
•	η εξοικείωση και ανάπτυξη των δεξιοτήτων των σπουδαστών στην εγκατάσταση και διαχείριση των κατανεμημένων συστημάτων Apache Spark και Apache Hadoop.
•	Η χρήση σύγχρονων τεχνικών μέσω των API του Spark για την ανάλυση δεδομένων όγκου.
•	H κατανόηση των δυνατοτήτων και περιορισμών των εργαλείων αυτών σε σχέση με τους διαθέσιμους πόρους και τις ρυθμίσεις που έχουν επιλεγεί.
-
Μέρος 1ο : Εξαγωγή Πληροφορίας - SQL
-
Περιγραφή Δεδομένων
Τα δεδομένα που θα χρησιμοποιήσετε είναι πραγματικά και αφορούν σε διαδρομές taxi στην Νέα Υόρκη. Οι δοθείσες διαδρομές των taxi έγιναν το 2024 και υπάρχουν διαθέσιμες online στο παρακάτω link:
https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
Έχουμε ανεβάσει στο HDFS του εργαστηρίου τα σύνολα δεδομένων πάνω στα οποία θα κάνετε την ανάλυση. Πρόκειται για 3 αρχεία:
-
Το πρώτο αρχείο περιλαμβάνει όλη την απαραίτητη πληροφορία για μια διαδρομή για το έτος 2024. Το αρχείο των TripData έχει την εξής μορφή:
yellow_tripdata_2024.csv
-
VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge,Airport_fee
1,2024-09-01T00:05:51.000,2024-09-01T00:45:03.000,1,9.8,1,N,138,48,1,47.8,10.25,0.5,13.3,6.94,1.0,79.79,2.5,1.75
1,2024-09-01T00:59:35.000,2024-09-01T01:03:43.000,1,0.5,1,N,140,141,1,5.1,3.5,0.5,3.0,0.0,1.0,13.1,2.5,0.0
2,2024-09-01T00:25:00.000,2024-09-01T00:34:37.000,2,2.29,1,N,238,152,2,13.5,1.0,0.5,0.0,0.0,1.0,16.0,0.0,0.0
2,2024-09-01T00:31:00.000,2024-09-01T00:46:52.000,1,5.2,1,N,93,130,1,24.7,1.0,0.5,4.55,0.0,1.0,31.75,0.0,0.0
2,2024-09-01T00:11:57.000,2024-09-01T00:30:41.000,2,2.26,1,N,79,231,1,17.0,1.0,0.5,4.4,0.0,1.0,26.4,2.5,0.0
1,2024-09-01T00:30:13.000,2024-09-01T00:36:44.000,1,1.2,1,N,43,239,1,8.6,3.5,0.5,2.7,0.0,1.0,16.3,2.5,0.0
1,2024-09-01T00:59:24.000,2024-09-01T01:01:00.000,1,0.1,5,N,143,143,3,0.01,0.0,0.0,0.0,0.0,1.0,1.01,0.0,0.0
1,2024-09-01T00:08:28.000,2024-09-01T00:39:06.000,4,9.8,1,N,93,161,1,44.3,3.5,0.5,9.85,0.0,1.0,59.15,2.5,0.0
1,2024-09-01T00:06:07.000,2024-09-01T00:11:38.000,1,0.6,1,N,170,137,1,6.5,3.5,0.5,2.9,0.0,1.0,14.4,2.5,0.0
-
Στον παρακάτω πίνακα γίνεται ανάλυση των πεδίων
-
Όνομα Πεδίου	        Περιγραφή
VendorID	            Κωδικός που υποδεικνύει τον πάροχο TPEP που παρείχε την εγγραφή. 1 = Creative Mobile Technologies, LLC; 2 = Curb Mobility, LLC; 6 = Myle Technologies Inc; 7 = Helix.
tpep_pickup_datetime	Ημερομηνία και ώρα που ενεργοποιήθηκε το ταξίμετρο.
tpep_dropoff_datetime	Ημερομηνία και ώρα που απενεργοποιήθηκε το ταξίμετρο.
passenger_count	        Αριθμός επιβατών στο όχημα.
trip_distance	        Απόσταση διαδρομής σε μίλια, όπως αναφέρεται από το ταξίμετρο.
RatecodeID	            Τελικός κωδικός τιμολόγησης στο τέλος της διαδρομής. 1 = Τυπικός ρυθμός; 2 = JFK; 3 = Newark; 4 = Nassau ή Westchester; 5 = Διαπραγματευόμενο ναύλο; 6 = Ομαδική διαδρομή; 99 = Άγνωστο/μη διαθέσιμο.
store_and_fwd_flag	    Δείκτης που υποδεικνύει αν η εγγραφή διαδρομής αποθηκεύτηκε στη μνήμη του οχήματος πριν αποσταλεί στον πάροχο. Y = αποθηκευμένη διαδρομή; N = μη αποθηκευμένη διαδρομή.
PULocationID	        Κωδικός ζώνης TLC όπου ενεργοποιήθηκε το ταξίμετρο (τοποθεσία επιβίβασης).
DOLocationID	        Κωδικός ζώνης TLC όπου απενεργοποιήθηκε το ταξίμετρο (τοποθεσία αποβίβασης).
payment_type	        Αριθμητικός κωδικός που υποδεικνύει τον τρόπο πληρωμής. 0 = Flex Fare διαδρομή; 1 = Πιστωτική κάρτα; 2 = Μετρητά; 3 = Χωρίς χρέωση; 4 = Αμφισβήτηση; 5 = Άγνωστο; 6 = Ακυρωμένη διαδρομή.
fare_amount	            Ναύλος που υπολογίζεται με βάση τον χρόνο και την απόσταση από το ταξίμετρο.
extra	                Επιπλέον χρεώσεις και προσαυξήσεις.
mta_tax	                Φόρος που ενεργοποιείται αυτόματα με βάση τον χρησιμοποιούμενο ρυθμό του ταξίμετρου.
tip_amount	            Ποσό φιλοδωρήματος – Αυτό το πεδίο συμπληρώνεται αυτόματα για φιλοδωρήματα με πιστωτική κάρτα. Τα μετρητά δεν περιλαμβάνονται.
tolls_amount	        Συνολικό ποσό όλων των διοδίων που πληρώθηκαν στη διαδρομή.
improvement_surcharge	Προσαύξηση βελτίωσης που επιβάλλεται στις διαδρομές κατά την έναρξη. Η προσαύξηση αυτή ξεκίνησε το 2015.
total_amount	        Συνολικό ποσό που χρεώθηκε στους επιβάτες. Δεν περιλαμβάνει μετρητά φιλοδωρήματα.
congestion_surcharge	Συνολικό ποσό που συλλέχθηκε στη διαδρομή για την προσαύξηση συμφόρησης της Νέας Υόρκης.
airport_fee            	Χρέωση για επιβιβάσεις μόνο στα αεροδρόμια LaGuardia και John F. Kennedy.
cbd_congestion_fee	    Χρέωση ανά διαδρομή για τη Ζώνη Ανακούφισης Συμφόρησης της MTA που ξεκίνησε στις 5 Ιανουαρίου 2025.
-
Το δεύτερο αρχείο περιέχει στοιχεία για τις διαδρομές του 2015 και περιέχει και συντεταγμένες GPS.
-
yellow_tripdata_2015.csv
Στον παρακάτω πίνακα γίνεται ανάλυση των πεδίων του 2015 dataset
-
Στήλη	Περιγραφή
VendorID	Αναγνωριστικό παρόχου (1 ή 2)
tpep_pickup_datetime	Ημερομηνία και ώρα επιβίβασης
tpep_dropoff_datetime	Ημερομηνία και ώρα αποβίβασης
passenger_count	Αριθμός επιβατών
trip_distance	Απόσταση διαδρομής σε μίλια
pickup_longitude	Γεωγραφικό μήκος επιβίβασης (σε μοίρες)
pickup_latitude	Γεωγραφικό πλάτος επιβίβασης (σε μοίρες)
RateCodeID	Τιμολογιακή ζώνη (1=Standard, 2=JFK, κ.λπ.)
store_and_fwd_flag	Αν αποθηκεύτηκε προσωρινά πριν αποσταλεί (Y/N)
dropoff_longitude	Γεωγραφικό μήκος αποβίβασης
dropoff_latitude	Γεωγραφικό πλάτος αποβίβασης
payment_type	Τρόπος πληρωμής (1=Credit, 2=Cash, κ.λπ.)
fare_amount	Ποσό ναύλου
extra	Πρόσθετα κόστη (π.χ. καιρός, νύχτα)
mta_tax	Φόρος MTA ($0.50)
tip_amount	Ποσό φιλοδωρήματος
tolls_amount	Ποσό για διόδια
improvement_surcharge	$0.30 από 2015 και μετά
total_amount	Συνολικό ποσό χρέωσης (fare + extras + tip + tolls + taxes + surcharges)
-
Το τρίτο αρχείο που σας δίνεται περιέχει πληροφορία για τις περιοχές της Νέας Υόρκης. 
Η μορφή του φαίνεται στο παρακάτω παράδειγμα:
taxi_zone_lookup.csv
-
"LocationID","Borough","Zone","service_zone"
1,"EWR","Newark Airport","EWR"
2,"Queens","Jamaica Bay","Boro Zone"
3,"Bronx","Allerton/Pelham Gardens","Boro Zone"
4,"Manhattan","Alphabet City","Yellow Zone"
-
Το αρχείο taxi_zone_lookup.csv περιέχει πληροφορίες για τις γεωγραφικές περιοχές της Νέας Υόρκης που χρησιμοποιούνται στα δεδομένα διαδρομών ταξί. Κάθε εγγραφή στο αρχείο αυτό αντιστοιχεί σε μια συγκεκριμένη ζώνη και περιλαμβάνει τα εξής πεδία:
-
•	LocationID: Ένας μοναδικός αριθμητικός αναγνωριστικός κωδικός για κάθε ζώνη.
•	Borough: Το όνομα του δήμου (borough) στον οποίο βρίσκεται η ζώνη, όπως "Manhattan", "Queens", "Brooklyn", "Bronx" ή "Staten Island".
•	Zone: Το όνομα της συγκεκριμένης ζώνης ή γειτονιάς μέσα στον δήμο.
•	service_zone: Η κατηγορία υπηρεσίας που εξυπηρετεί η ζώνη. Οι πιθανές τιμές περιλαμβάνουν:
o	"Yellow Zone": Ζώνες που εξυπηρετούνται κυρίως από τα κίτρινα ταξί.
o	"Boro Zone": Ζώνες εκτός του κεντρικού Μανχάταν που εξυπηρετούνται από πράσινα ταξί ή άλλες υπηρεσίες.
o	"EWR": Αναφέρεται στο Αεροδρόμιο Newark.
-
Αυτά τα πεδία επιτρέπουν τη συσχέτιση των LocationID που εμφανίζονται στα δεδομένα διαδρομών ταξί με συγκεκριμένες γεωγραφικές περιοχές και κατηγορίες υπηρεσιών.
Τα σύνολα δεδομένων και οι τοποθεσίες τους στο HDFS φαίνονται στο παρακάτω πίνακα.
-
Σύνολο Δεδομένων	HDFS URI
yellow_tripdata_2024.csv	hdfs://hdfs-namenode:9000/data/yellow_tripdata_2024.csv
yellow_tripdata_2015.csv	hdfs://hdfs-namenode:9000/data/yellow_tripdata_2015.csv
taxi_zone_lookup.csv	hdfs://hdfs-namenode:9000/data/taxi_zone_lookup.csv
-
1Α. Εξαγωγή πληροφορίας με διαφορετικούς τρόπους
Παρόλο που τα δεδομένα δίνονται σε μορφή απλού κειμένου (csv), είναι γνωστό ότι ο υπολογισμός ερωτημάτων αναλυτικής επεξεργασίας απευθείας πάνω σε αρχεία csv δεν είναι αποδοτικός. Για να βελτιστοποιηθεί η πρόσβαση των δεδομένων, παραδοσιακά οι βάσεις δεδομένων φορτώνουν τα δεδομένα σε ειδικά σχεδιασμένα binary formats. 
Παρ’ότι το Spark δεν είναι μια τυπική βάση δεδομένων, αλλά ένα σύστημα κατανεμημένης επεξεργασίας, για λόγους απόδοσης, υποστηρίζει κι αυτό μια παρόμοια λογική. Αντί να τρέξουμε τα ερωτήματά μας απευθείας πάνω στα csv αρχεία, μπορούμε να μετατρέψουμε πρώτα το dataset σε μια ειδική μορφή που: 
-
●	Έχει μικρότερο αποτύπωμα στη μνήμη και στον δίσκο και άρα βελτιστοποιεί το I/O (input/output) μειώνοντας τον χρόνο εκτέλεσης.
-
●	Διατηρεί επιπλέον πληροφορία, όπως στατιστικά πάνω στο dataset, τα οποία βοηθούν στην πιο αποτελεσματική επεξεργασία του. Για παράδειγμα, αν ψάχνω σε ένα σύνολο δεδομένων τις τιμές που είναι μεγαλύτερες από 100 και σε κάθε block του dataset έχω πληροφορία γιαυτό ποια είναι η min και ποια η max τιμή, τότε μπορώ να παρακάμψω την επεξεργασία των blocks με max τιμή < 100 γλιτώνοντας έτσι χρόνο επεξεργασίας.
-
Το πρόβλημα που καλείστε να αντιμετωπίσετε είναι ο υπολογισμός των ερωτημάτων του Πίνακα 1 για την εξαγωγή πληροφορίας από τα δεδομένα με δύο διαφορετικούς τρόπους:
●	Γράφοντας MapReduce κώδικα χρησιμοποιώντας το RDD API του Spark
●	Χρησιμοποιώντας SparkSQL και το DataFrame API
-
Πιο συγκεκριμένα, θα πρέπει να κάνετε τα εξής:
1.	Φορτώστε τα csv αρχεία που σας δίνονται στο HDFS. 
-
2.	Υλοποιήστε και τρέξτε τα ερωτήματα του Πίνακα 1 με χρήση:
a.	MapReduce κώδικα. Η υλοποίηση θα πρέπει να τρέξει απευθείας πάνω στα αρχεία κειμένου. 
b.	SparkSQL. Φορτώστε τα αρχεία κειμένου σε Dataframes και εκτελέστε τα ερωτήματα με χρήση της SparkSQL. 
-
3.	Μετατρέψτε τα αρχεία κειμένου σε αρχεία Parquet. Στη συνέχεια φορτώστε τα Parquet αρχεία ως Dataframes και εκτελέστε το υποερώτημα 2b. Πόσος χρόνος χρειάζεται για τη μετατροπή των αρχείων; 
-
4.	Για κάθε ερώτημα του Πίνακα 1, συγκρίνετε και φτιάξτε ένα διάγραμμα με τον χρόνο εκτέλεσης των παραπάνω περιπτώσεων, δηλαδή:
a.	MR πάνω σε csv αρχεία.
b.	SQL πάνω σε csv αρχεία. 
c.	SQL πάνω σε Parquet αρχεία. (Διευκρίνιση: Τα SQL ερωτήματα θα πρέπει να τρέξουν σε Dataframes που έχουν δημιουργηθεί  είτε από αρχεία κειμένου είτε από αρχεία Parquet).
-
Σχολιάστε τα αποτελέσματά σας.
-
Πίνακας 1
-
ID	Query
-
Q1	Για κάθε ώρα της ημέρας (00 έως 23), υπολογίστε τη μέση τιμή των γεωγραφικών συντεταγμένων (πλάτος και μήκος) σημείου επιβίβασης, αγνοώντας εγγραφές με μηδενικές συντεταγμένες. Ταξινομήστε το αποτέλεσμα          αύξουσα ως προς την ώρα.
    Χρησιμοποιήστε το 2015 dataset
    Ενδεικτικά αποτελέσματα:
 -   
    HourOfDay		Latitude                   Longitude
    00			      -73,...                    40,...
    01			      -73,...                    40,...
-    
Q2	Για κάθε Vendor (πάροχο ταξί), υπολογίστε τη μέγιστη απόσταση διαδρομής που πραγματοποιήθηκε, μετρώντας την απόσταση ως γεωδαισιακή απόσταση Haversine μεταξύ του σημείου επιβίβασης και του σημείου αποβίβασης.
    Χρησιμοποιήστε το 2015 dataset
    Επιπλέον, επιστρέψτε και τη χρονική διάρκεια της διαδρομής στην οποία παρατηρήθηκε η μέγιστη απόσταση.
    
    VendorID	Max Haversine Distance (km)	Duration (min)
    1	              38.72	                    47.3
    2	              42.15	                    53.8
    6	              34.90	                    41.5
    7	              39.35                    	46.2
-
Q3	Για κάθε δήμο (Borough) της Νέας Υόρκης, υπολογίστε τον συνολικό αριθμό διαδρομών ταξί που ξεκίνησαν και κατέληξαν στον συγκεκριμένο δήμο.
    Ταξινομήστε το τελικό αποτέλεσμα κατά φθίνουσα σειρά ως προς τον αριθμό των διαδρομών.
    Χρησιμοποιήστε το 2024 dataset
    
    Ενδεικτικά αποτελέσματα:
    Borough	    TotalTrips
    Manhattan	    124520
    Queens	      78250
    Brooklyn	    45200
    Bronx	        36710
-
Q4	Υπολογίστε τον συνολικό αριθμό διαδρομών ταξί που πραγματοποιήθηκαν μεταξύ 23:00 και 07:00, ανεξαρτήτως τοποθεσίας.
    Εξάγετε την ώρα από το πεδίο tpep_pickup_datetime και κρατήστε μόνο τις εγγραφές:
    •	είτε από 23:00 έως 23:59
    •	είτε από 00:00 έως 06:59
    Στη συνέχεια, ομαδοποιήστε τα αποτελέσματα ανά VendorID, ώστε να φανεί πόσες νυχτερινές διαδρομές πραγματοποιήθηκαν από κάθε πάροχο.
    Χρησιμοποιήστε το 2024 dataset
-
    Ενδεικτικά αποτελέσματα
    VendorID	NightTrips
    1	          54,820
    2	          47,210
-
Q5	Εντοπίστε τα ζεύγη ζωνών (Zone) με τον μεγαλύτερο αριθμό μετακινήσεων μεταξύ τους, βάσει των διαδρομών ταξί.
    Εξαιρούνται οι περιπτώσεις όπου η διαδρομή ξεκίνησε και κατέληξε στην ίδια υπο-περιοχή.
    Το αποτέλεσμα πρέπει να ομαδοποιεί ανά ζεύγος PickupZone → DropoffZone και να εμφανίζει το πλήθος διαδρομών ανά ζεύγος. Ταξινομήστε φθίνουσα με βάση τον αριθμό των μετακινήσεων.
    Χρησιμοποιήστε το 2024 dataset
    Ενδεικτικά αποτελέσματα:
-    
    Pickup Zone	      Dropoff Zone	        TotalTrips
    Midtown Center	  Upper East Side  	      32140
    Upper West Side	  Times Square	          28790
    JFK Airport	      Midtown Center	        25310
    Chelsea	          Financial District	    19840
-
Q6	Για κάθε δήμο (Borough) από τον οποίο ξεκίνησε μία διαδρομή ταξί, υπολογίστε τα συνολικά έσοδα από τις διαδρομές που ξεκίνησαν από αυτόν.
    Αναλύστε τα συνολικά έσοδα σε επιμέρους κατηγορίες χρεώσεων:
    •	fare_amount (βασικός ναύλος),
    •	tip_amount (φιλοδώρημα),
    •	tolls_amount (διόδια),
    •	extra (επιπλέον χρεώσεις),
    •	mta_tax (φόρος MTA),
    •	congestion_surcharge (προσαύξηση συμφόρησης),
    •	airport_fee (χρέωση αεροδρομίου),
    •	total_amount (συνολικό ποσό χρέωσης).
    Ταξινομήστε τα αποτελέσματα κατά φθίνουσα σειρά με βάση τα συνολικά έσοδα (total_amount) για να εντοπίσετε τους δήμους με τη μεγαλύτερη οικονομική δραστηριότητα.
    Χρησιμοποιήστε το 2024 dataset
-
    Ενδεικτικά αποτελέσματα:
    Borough	          Fare ($)	        Tips ($)	      Tolls ($)	      Extras ($)	    MTA Tax ($)	    Congestion ($)	    Airport Fee ($)	    Total Revenue ($)
    Manhattan	    1,254,320.50	  234,189.75	      112,340.00	    95,812.40	      52,130.00	        88,390.00	          19,230.00	         1,856,412.65
    Queens	    874,520.30	      132,450.20	      98,420.00	      54,210.75	      36,740.00	        45,210.00	          12,800.00	         1,254,351.25
    Brooklyn	    432,105.80	    64,891.55	        41,295.00	      28,675.60	      18,330.00	        22,870.00	          4,310.00	         612,478.95
    Bronx	        216,430.25	    21,840.00	        12,760.00	      14,380.90	      9,200.00	        10,890.00	          1,210.00	         286,711.15
    Staten Isl.	  42,350.00	      3,240.00	        2,180.00	      1,985.20	      1,080.00	        880.00	            0.00	             51,715.20
-
Σημειώσεις-Υποδείξεις
-
1.	Κάθε γραμμή του αρχείου που διαβάζουμε με το RDD API φορτώνεται στη μνήμη ως string. Aφού εξάγουμε τις επιθυμητές στήλες από τη γραμμή, για να κάνουμε πράξεις με κάποιες στήλες θα πρέπει οι τιμές να μετατραπούν από string στον κατάλληλο τύπο πρώτα. Τις ημερομηνίες π.χ. μπορούμε να τις μετατρέψουμε κατάλληλα χρησιμοποιώντας τη μορφή '%Y-%m-%d %H:%M:%S'.
-
2.	Για το Q2, η ταχύτητα μιας κούρσας ορίζεται ως η απόσταση που διανύθηκε προς τον χρόνο που χρειάστηκε. 
-
3.	Υπολογισμός απόστασης (Haversine ). Αν φ είναι το γεωγραφικό πλάτος και λ το γεωγραφικό μήκος, τότε η απόσταση δύο σημείων δίνεται από τους τύπους: 
a = sin²(Δφ/2) + cos φ1 ⋅ cos φ2 ⋅ sin²(Δλ/2)
c = 2 ⋅ atan2( √a, √(1−a) )
d = R ⋅ c, όπου R είναι η ακτίνα της Γης (6371m)
-
1Β. Μελέτη του βελτιστοποιητή για την συνένωση δεδομένων.
-
To SparkSQL έχει υλοποιημένα και τα δύο είδη ερωτημάτων συνένωσης στο DataFrame API. Συγκεκριμένα, με βάση τη δομή των δεδομένων και των υπολογισμών που θέλουμε καθώς και τις ρυθμίσεις του χρήστη, πραγματοποιεί από μόνο του κάποιες βελτιστοποιήσεις στην εκτέλεση του ερωτήματος χρησιμοποιώντας έναν βελτιστοποιητή ερωτημάτων (query optimizer), κάτι που όλες οι βάσεις δεδομένων έχουν. Μια τέτοια βελτιστοποίηση είναι ότι επιλέγει αυτόματα την υλοποίηση που θα χρησιμοποιήσει για ένα ερώτημα join λαμβάνοντας υπόψη το μέγεθος των δεδομένων και πολλές φορές αλλάζει και την σειρά ορισμένων τελεστών προσπαθώντας να μειώσει τον συνολικό χρόνο εκτέλεσης του ερωτήματος. Αν ο ένας πίνακας είναι αρκετά μικρός (με βάση ένα όριο που ρυθμίζει ο χρήστης)  θα χρησιμοποιήσει το broadcast join, αλλιώς θα κάνει ένα repartition join. Περισσότερες πληροφορίες για τις ρυθμίσεις βελτιστοποίησης του SparkSQL υπάρχουν εδώ: https://spark.apache.org/docs/latest/sql-performance-tuning.html. 
Για την μελέτη της επίδρασης του βελτιστοποιητή στην εκτέλεση των ερωτημάτων συνένωσης, στη συνέχεια της εργασίας καλείστε να εκτελέσετε τα παρακάτω:
-
1.	Απομονώστε τις 50 πρώτες γραμμές από το αρχείο με τις εταιρείες ταξί και εκτελέσετε με SparkSQL ένα join πάνω στα 2 parquet αρχεία και πάρτε πίσω όλα τα δεδομένα. Εντοπίστε ποια υλοποίηση join χρησιμοποίησε το Spark. Γιατί επιλέχθηκε η συγκεκριμένη υλοποίηση; 
Υπόδειξη: Μπορείτε να χρησιμοποιήσετε το ‘explain’ statement της SQL για να δείτε τις λεπτομέρειες του πλάνου εκτέλεσης. Αιτιολογήστε την απάντησή σας με βάση το πλάνο εκτέλεσης του ερωτήματος και τις προκαθορισμένες ρυθμίσεις του Spark. Για να απομονώσετε τις 50 εγγραφές μπορείτε να φτιάξετε ένα εμβόλιμο ερώτημα στο ερώτημα συνένωσης, το οποίο θα απομονώνει τις πρώτες 100 εγγραφές (limit).
-
2.	Ρυθμίστε κατάλληλα το Spark χρησιμοποιώντας τις ρυθμίσεις του βελτιστοποιητή ώστε να μην επιλέγει την υλοποίηση join του προηγούμενου ερωτήματος. Σε πόσο χρόνο εκτελείται τώρα το ερώτημα και ποια υλοποίηση join χρησιμοποίησε το Spark αυτή τη φορά; Συγκρίνετε τον χρόνο εκτέλεσης των δύο υποερωτημάτων. 
-
Ζητούμενα
-
•	Να ολοκληρωθεί η διαδικασία σύνδεσης με την απομακρυσμένη υποδομή kubernetes που περιγράφεται στους οδηγούς του μαθήματος. Επίσης, να ολοκληρωθεί η διαδικασία παραμετροποίησης του Spark Job History Server μέσω docker και docker compose τοπικά, στο μηχάνημά σας, ώστε να αντλεί τα δεδομένα από τις εκτελέσεις σας στην απομακρυσμένη υποδομή (HDFS). 
-
•	Να γραφτεί κώδικας που θα διαβάσει τα αρχεία δεδομένων και με την κατάλληλη επεξεργασία θα τα αποθηκεύσει σε μορφή parquet στο HDFS, στο παρακάτω path: 
hdfs://hdfs-namenode:9000/user/{username}/data/parquet/
-
Δώστε ιδιαίτερη προσοχή στο αρχείο που αντιστοιχεί στο dataset yellow_tripdata_2024, καθώς δε βρίσκεται σε εξαρχής σε μορφή που το Spark μπορεί να αναγνωρίσει. 
•	Να υλοποιηθεί το Query 1 χρησιμοποιώντας τα RDD και DataFrame APIs (με udf και χωρίς). Σχολιάστε τις διαφορές στην επίδοση μεταξύ των διαφορετικών υλοποιήσεών σας. 
•	Να υλοποιηθεί το Query 2 χρησιμοποιώντας τα RDD, DataFrame και SQL APIs. Σχολιάστε τις επιδόσεις των υλοποιήσεών σας. 
•	Να υλοποιηθεί το Query 3 χρησιμοποιώντας α) τo DataFrame API και β) το SQL API. Πειραματιστείτε κάνοντας την εισαγωγή των δεδομένων με χρήση αρχείων csv και parquet και σχολιάστε πώς επηρεάζεται η εκτέλεση.
•	Να υλοποιηθεί το Query 4 χρησιμοποιώντας τo SQL API. Πειραματιστείτε κάνοντας την εισαγωγή των δεδομένων με χρήση αρχείων csv και parquet και σχολιάστε πώς επηρεάζεται η εκτέλεση. 
•	Να υλοποιηθεί το Query 5 χρησιμοποιώντας τo DataFrame API. Πειραματιστείτε κάνοντας την εισαγωγή των δεδομένων με χρήση αρχείων csv και parquet και σχολιάστε πώς επηρεάζεται η εκτέλεση. 
•	Να υλοποιηθεί το Query 6 χρησιμοποιώντας τo DataFrame API. Εφαρμόστε οριζόντια και κάθετη κλιμάκωση (horizontal and vertical scaling) των πόρων που δεσμεύετε για την εκτέλεση χρησιμοποιώντας τα κατάλληλα spark configurations (spark.executor.instances, spark.executor.cores, spark.executor.memory). 
-
Καλείστε να εκτελέσετε την υλοποίησή σας χρησιμοποιώντας συνολικούς πόρους 8 cores και 16GB μνήμης με τα παρακάτω configurations:
•	2 executors X 4 cores/8GB memory
•	4 executors X 2 cores/4GB memory
•	8 executors X 1 core/2 GB memory
-
Σχολιάστε τα αποτελέσματα. 
•	Για κάθε ένα από τα joins των υλοποιήσεων των Query 3, 4 και Query 5 να αναφερθεί η επιλογή στρατηγικής (BROADCAST, MERGE, SHUFFLE_HASH, SHUFFLE_REPLICATE_NL κλπ.) που κάνει ο Catalyst Optimizer του Spark με χρήση της εντολής explain ή του Job History Server (να συμπεριληφθεί το σχετικό output ή screenshot). 
Να σχολιάσετε βάσει θεωρίας αν η επιλογή δικαιολογείται ή όχι βάσει των χαρακτηριστικών του join. 
-
-
2024-2025
